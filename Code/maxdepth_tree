###DECISION TREE####

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import math
import warnings
warnings.filterwarnings("ignore")
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn import preprocessing
from sklearn import tree
import seaborn as sns
import sklearn.metrics as metrics

from sklearn.model_selection import GridSearchCV

url = 'https://github.com/JichongWu/Final-Project-Group8/blob/main/Data/project_original_J.Pai.csv?raw=true'
project = pd.read_csv(url, encoding='ISO-8859-1')
print(project.head(5))
list(project.columns.values)
project.target = project.ROLL

from sklearn import preprocessing
from sklearn import tree
import pydotplus
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt
import matplotlib.image as pltimg

le = preprocessing.LabelEncoder()
encoded_df = (project.apply(le.fit_transform))
features = ['WEATHER_GROUP', 'LIGHT_GROUP', 'SURFACE_GROUP', 'GRADE_GROUP','VEHICLE_TYPE','ALIGN_GROUP','SEX', 'AGE','MY_GROUP']
y = encoded_df['ROLL']
X = pd.DataFrame(encoded_df[features])
y = pd.DataFrame(encoded_df['ROLL'])


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)


clf_entropy = tree.DecisionTreeClassifier(criterion="entropy", random_state=8, splitter = "best", max_depth=3, min_samples_leaf=5)
clf_entropy = clf_entropy.fit(X_train, y_train)


data = tree.export_graphviz(clf_entropy, out_file=None, feature_names=features)
graph = pydotplus.graph_from_dot_data(data)
graph.write_png('mydecisiontree.png')

img=pltimg.imread('mydecisiontree.png')
imgplot = plt.imshow(img)
plt.show()


#MAX DEPTH
import numpy as np
import matplotlib.pyplot as plt

max_depth_list = np.arange(1,15,1)
acc_entropy = []
for x in max_depth_list:
    dtc = DecisionTreeClassifier(max_depth=x)
    dtc.fit(X_train, y_train)
	pred = dtc.predict(X_test)
	acc_entropy.append(accuracy_score(y_test, pred))

x = np.arange(len(max_depth_list)) + 1 # Create domain for plot
plt.plot(x, acc_entropy, label = acc_entropy) # Plot training error over domain
plt.xlabel('Maximum Depth') # Label x-axis
plt.ylabel('Accuracy') # Label y-axis
plt.legend() # Show plot labels as legend
plt.plot() # Show graph
plt.show()



##FEATURE IMPORTNACE 
importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(clf_entropy.feature_importances_,3)})
importances = importances.sort_values('importance',ascending=False)
print(importances)


##OVERFITTING 


####OVERFITTING AUC GRAPH
le = preprocessing.LabelEncoder()
encoded_df = (project.apply(le.fit_transform))
features = ['WEATHER_GROUP', 'LIGHT_GROUP', 'SURFACE_GROUP', 'GRADE_GROUP','VEHICLE_TYPE','ALIGN_GROUP','SEX', 'AGE','MY_GROUP']
y = encoded_df['ROLL']
X = pd.DataFrame(encoded_df[features])
y = pd.DataFrame(encoded_df['ROLL'])


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)


dt= DecisionTreeClassifier()
dt.fit(X_train, y_train)
DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None, max_features=None, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, random_state=8, splitter='best')

y_pred = dt.predict(X_test)

from sklearn.metrics import roc_curve, auc
false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)
roc_auc = auc(false_positive_rate, true_positive_rate)

max_depths = np.linspace(1, 20, 20, endpoint=True)
train_results = []
test_results = []
for max_depth in max_depths:
   dt = DecisionTreeClassifier(max_depth=max_depth)
   dt.fit(X_train, y_train)
   train_pred = dt.predict(X_train)
   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)
   roc_auc = auc(false_positive_rate, true_positive_rate)
   # Add auc score to previous train results
   train_results.append(roc_auc)
   y_pred = dt.predict(X_test)
   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)
   roc_auc = auc(false_positive_rate, true_positive_rate)
   # Add auc score to previous test results
   test_results.append(roc_auc)

from matplotlib.legend_handler import HandlerLine2D
line1, = plt.plot(max_depths, train_results, 'b', label="Train AUC")
line2, = plt.plot(max_depths, test_results, 'r', label="Test AUC")
plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
plt.ylabel('AUC score')
plt.xlabel('Tree depth')
plt.show()

