###DECISION TREE####

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import math
import warnings
warnings.filterwarnings("ignore")
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn import preprocessing
from sklearn import tree
import seaborn as sns
import sklearn.metrics as metrics

from sklearn.model_selection import GridSearchCV

url = 'https://github.com/JichongWu/Final-Project-Group8/blob/main/Data/project_original_J.Pai.csv?raw=true'
project = pd.read_csv(url, encoding='ISO-8859-1')
print(project.head(5))
list(project.columns.values)
project.target = project.ROLL

from sklearn import preprocessing
from sklearn import tree
import pydotplus
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt
import matplotlib.image as pltimg

le = preprocessing.LabelEncoder()
encoded_df = (project.apply(le.fit_transform))
features = ['WEATHER_GROUP', 'LIGHT_GROUP', 'SURFACE_GROUP', 'GRADE_GROUP','VEHICLE_TYPE','ALIGN_GROUP','SEX', 'AGE','MY_GROUP']
y = encoded_df['ROLL']
X = pd.DataFrame(encoded_df[features])
y = pd.DataFrame(encoded_df['ROLL'])


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)


clf_entropy = tree.DecisionTreeClassifier(criterion="entropy", random_state=8, splitter = "best", max_depth=3, min_samples_leaf=5)
clf_entropy = clf_entropy.fit(X_train, y_train)


data = tree.export_graphviz(clf_entropy, out_file=None, feature_names=features)
graph = pydotplus.graph_from_dot_data(data)
graph.write_png('mydecisiontree.png')

img=pltimg.imread('mydecisiontree.png')
imgplot = plt.imshow(img)
plt.show()

#Best Depth for accuracy #THIS IS WHAT I CANNOT GET TO GRAPH
# List of values to try for max_depth:
max_depth = []
acc_gini = []
acc_entropy = []
for i in range(1,50):
 dtree = DecisionTreeClassifier(criterion='gini', random_state=8, max_depth=i)
 dtree.fit(X_train, y_train)
 pred = dtree.predict(X_test)
 acc_gini.append(accuracy_score(y_test, pred))
 ####
 dtree = DecisionTreeClassifier(criterion='entropy', random_state=8, max_depth=i)
 dtree.fit(X_train, y_train)
 pred = dtree.predict(X_test)
 acc_entropy.append(accuracy_score(y_test, pred))
 ####
 max_depth.append(i)
d = pd.DataFrame({'acc_gini':(acc_gini),
                  'acc_entropy':(acc_entropy), 'max_depth':(max_depth)})
print(d)

plt.plot(max_depth,acc_gini, data=d)
plt.plot(max_depth,acc_entropy, data=d)
plt.legend()

##FEATURE IMPORTNACE 
importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(clf_entropy.feature_importances_,3)})
importances = importances.sort_values('importance',ascending=False)
print(importances)

