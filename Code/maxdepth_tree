###DECISION TREE####

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import math
import warnings
warnings.filterwarnings("ignore")
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn import preprocessing
from sklearn import tree
import seaborn as sns
import sklearn.metrics as metrics

from sklearn.model_selection import GridSearchCV

url = 'https://github.com/JichongWu/Final-Project-Group8/blob/main/Data/project_original_J.Pai.csv?raw=true'
project = pd.read_csv(url, encoding='ISO-8859-1')
print(project.head(5))
list(project.columns.values)
project.target = project.ROLL

from sklearn import preprocessing
from sklearn import tree
import pydotplus
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt
import matplotlib.image as pltimg

le = preprocessing.LabelEncoder()
encoded_df = (project.apply(le.fit_transform))
features = ['WEATHER_GROUP', 'LIGHT_GROUP', 'SURFACE_GROUP', 'GRADE_GROUP','VEHICLE_TYPE','ALIGN_GROUP','SEX', 'AGE','MY_GROUP']
y = encoded_df['ROLL']
X = pd.DataFrame(encoded_df[features])
y = pd.DataFrame(encoded_df['ROLL'])


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)


clf_entropy = tree.DecisionTreeClassifier(criterion="entropy", random_state=8, splitter = "best", max_depth=3, min_samples_leaf=5)
clf_entropy = clf_entropy.fit(X_train, y_train)


data = tree.export_graphviz(clf_entropy, out_file=None, feature_names=features)
graph = pydotplus.graph_from_dot_data(data)
graph.write_png('mydecisiontree.png')

img=pltimg.imread('mydecisiontree.png')
imgplot = plt.imshow(img)
plt.show()


#MAX DEPTH
import numpy as np
import matplotlib.pyplot as plt

max_depth_list = np.arange(1,15,1)
acc_entropy = []
for x in max_depth_list:
    dtc = DecisionTreeClassifier(max_depth=x)
    dtc.fit(X_train, y_train)
	pred = dtc.predict(X_test)
	acc_entropy.append(accuracy_score(y_test, pred))

x = np.arange(len(max_depth_list)) + 1 # Create domain for plot
plt.plot(x, acc_entropy, label = acc_entropy) # Plot training error over domain
plt.xlabel('Maximum Depth') # Label x-axis
plt.ylabel('Accuracy') # Label y-axis
plt.legend() # Show plot labels as legend
plt.plot() # Show graph
plt.show()



##FEATURE IMPORTNACE 
importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(clf_entropy.feature_importances_,3)})
importances = importances.sort_values('importance',ascending=False)
print(importances)

